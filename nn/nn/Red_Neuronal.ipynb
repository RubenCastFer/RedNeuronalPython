{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "OYT1ubo0n1AR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FXy6hy4i8Zl"
      },
      "source": [
        "# Definición del modelo en python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZY5Nz2qhJ_0"
      },
      "source": [
        "Creamos la clase nodo sobre los que implementaremos las neuronas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "yPH-gy2WoEMB"
      },
      "outputs": [],
      "source": [
        "class NetNode(object):\n",
        "    \"\"\" Base class that represents a node in a neural net \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.inputs = []\n",
        "        self.weights = []\n",
        "        self.value = None\n",
        "    def __str__(self) -> str:\n",
        "        i = '-'.join(str(x) for x in self.inputs) + \"\"\n",
        "        w = '-'.join(str(x) for x in self.inputs) + \"\"\n",
        "        return str(self.value) + \" I:[\" + \"\".join(map(str,self.inputs)) + \"] W:[\" + \"\".join(map(str,self.weights)) +\"]\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clases para la configuración de las neuronas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sigmoide():\n",
        "    def act(z):\n",
        "        return 1/(1+np.exp(-z))\n",
        "    def prime(z):\n",
        "        return Sigmoide.act(z) * (1- Sigmoide.act(z))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReLu():\n",
        "    def act(z):\n",
        "        return max(0, z)\n",
        "    \n",
        "    def prime(z):\n",
        "        return 1 if z > 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JFbPgmjhTil"
      },
      "source": [
        "A continuación crearemos la estructura de la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "axystQQEpnjL"
      },
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "    \"\"\" Main class to construct ant train neural networks \"\"\"\n",
        "\n",
        "    def __init__(self, layers, funcionDeActivacion):\n",
        "        \"\"\" \n",
        "        Parameters\n",
        "        ----------\n",
        "        layers:\n",
        "            A list that represents the neurons and layers of the network.\n",
        "            For example, [2, 3, 1] represents a network with 3 layers:\n",
        "            - input layer: 2 neurons.\n",
        "            - hidden layer: 3 neurons.\n",
        "            - output layer: 1 neuron. \n",
        "        \"\"\"\n",
        "\n",
        "        # Funciones\n",
        "        self.funcionDeActivacion=funcionDeActivacion\n",
        "        #Creamos la estructura\n",
        "        self.net = [[NetNode() for _ in range(size)] for size in layers]\n",
        "\n",
        "        #Realizamos las conexiones y establecemos el peso por omisión a 0\n",
        "        sizes = len(layers)\n",
        "        # Make connections\n",
        "        for layer in range(1, sizes):\n",
        "            for node in self.net[layer]:\n",
        "                for unit in self.net[layer - 1]:\n",
        "                    node.inputs.append(unit)\n",
        "                    node.weights.append(0)\n",
        "\n",
        "    #Predicción para los datos de entrada\n",
        "    def predict(self, input_data):\n",
        "        inputs = self.net[0]\n",
        "\n",
        "        # Initialize inputs\n",
        "        for v, n in zip(input_data, inputs):\n",
        "            n.value = v\n",
        "\n",
        "        # Forward step, comenzamos en la priemra capa oculta\n",
        "        for layer in self.net[1:]:\n",
        "            for node in layer:\n",
        "                in_val = [n.value for n in node.inputs]\n",
        "                #Aplicamos los pesos de los valores de entrada\n",
        "                unit_value = np.dot(in_val, node.weights)\n",
        "                node.value = self.funcionDeActivacion[self.net.index(layer)-1].act(unit_value)\n",
        "\n",
        "        #Como resultado de la predicción devolvemos los índices del array de salida\n",
        "        \n",
        "\n",
        "        #Damos como salida el nodo ccuyo valor sea máximo. O lo que es lo mismo,\n",
        "        # devolvemos el nodo que caracteriza a la clase de los datos de entrada.\n",
        "        outputs = self.net[-1]     \n",
        "        result = outputs.index(max(outputs, key=lambda node: node.value))      \n",
        "        return result\n",
        "\n",
        "    def accuracy(self, examples):\n",
        "        correct = 0\n",
        "\n",
        "        for x_test, y_test in examples:\n",
        "            prediction = self.predict(x_test)\n",
        "\n",
        "            if (y_test[prediction] == 1):\n",
        "                correct += 1\n",
        "\n",
        "        return correct / len(examples)\n",
        "\n",
        "    #Eta es la tasa dxe aprendizaje\n",
        "    #epochs el número de iteraciones\n",
        "    def backpropagation(self, eta, examples, epochs):\n",
        "        inputs = self.net[0]\n",
        "        outputs = self.net[-1]\n",
        "        layer_size = len(self.net)\n",
        "\n",
        "        # Initialize weights con un valor aleatorio para todas las capas menos\n",
        "        # para la de entrada\n",
        "        for layer in self.net[1:]:\n",
        "            for node in layer:\n",
        "                node.weights = [np.random.uniform()\n",
        "                                for _ in range(len(node.weights))]\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for x_train, y_train in examples:\n",
        "                # Initialize inputs\n",
        "                for value, node in zip(x_train, inputs):\n",
        "                    node.value = value\n",
        "\n",
        "                # Forward step\n",
        "                for layer in self.net[1:]:\n",
        "                    # print(\"En forward utilizo \" + str(self.funcionDeActivacion[self.net.index(layer)-1]) + \" para la capa \" + str(self.net.index(layer))) \n",
        "                    for node in layer:\n",
        "                        in_val = [n.value for n in node.inputs]\n",
        "                        unit_value = np.dot(in_val, node.weights)\n",
        "                        node.value = self.funcionDeActivacion[self.net.index(layer)-1].act(unit_value)\n",
        "\n",
        "                # Initialize delta\n",
        "                delta = [[] for _ in range(layer_size)]\n",
        "\n",
        "                # Error for the MSE cost function\n",
        "                err = [y_train[i] -\n",
        "                       outputs[i].value for i in range(len(outputs))]\n",
        "\n",
        "                delta[-1] = [self.funcionDeActivacion[self.net.index(layer)-1].prime(outputs[i].value) * err[i]\n",
        "                             for i in range(len(outputs))]\n",
        "\n",
        "                # Backward step\n",
        "                hidden_layers = layer_size - 2\n",
        "                for i in range(hidden_layers, 0, -1):\n",
        "\n",
        "                    layer = self.net[i]\n",
        "                    n_layers = len(layer)\n",
        "                    # print(\"En Backward utilizo \" + str(self.funcionDeActivacion[i-1]) + \" para la capa \" + str(self.net.index(layer))) \n",
        "\n",
        "                    # Weights from the last layer\n",
        "                    w = [[node.weights[l] for node in self.net[i + 1]]\n",
        "                         for l in range(n_layers)]\n",
        "\n",
        "                    delta[i] = [self.funcionDeActivacion[i-1].prime(\n",
        "                        layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
        "\n",
        "                # Update weights\n",
        "                for i in range(1, layer_size):\n",
        "                    layer = self.net[i]\n",
        "                    in_val = [node.value for node in self.net[i - 1]]\n",
        "                    n_layers = len(self.net[i])\n",
        "                    for j in range(n_layers):\n",
        "                        layer[j].weights = np.add(\n",
        "                            layer[j].weights, np.multiply(eta * delta[i][j], in_val))\n",
        "\n",
        "            print(f\"epoch {epoch}/{epochs} | total error={np.sum(err)/len(examples)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2TmVbP5ixib"
      },
      "source": [
        "# Prueba del modelo implementado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKrOfyBii0CJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "IVu3NqFcIvLy"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "IAK3KrAJI1W2"
      },
      "outputs": [],
      "source": [
        "# import data to play with\n",
        "iris_X, iris_y = datasets.load_iris(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjdRoh7TVRpP",
        "outputId": "6d364370-1c0b-4b1e-a375-dccd9c0ff492"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1]])"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First 10 elements of input data\n",
        "iris_X[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4xiB-m_VsYe",
        "outputId": "785835f1-5f72-48ee-a0b1-acf574f39e1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First 10 elements of output data\n",
        "iris_y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "z7xTNaOELN3a"
      },
      "outputs": [],
      "source": [
        "iris_x_normalized = normalize(iris_X, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "tACz7erfLWM_"
      },
      "outputs": [],
      "source": [
        "# Creating train and test data\n",
        "'''\n",
        "80% -- train data\n",
        "20% -- test data\n",
        "'''\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_x_normalized, iris_y, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "HWdy34sgLZ9f"
      },
      "outputs": [],
      "source": [
        "# Convert classes from categorical ('Setosa', 'Versicolor', 'Virginica')\n",
        "# to numerical (0, 1, 2) and then to one-hot encoded ([1, 0, 0], [0, 1, 0], [0, 0, 1]).\n",
        "'''\n",
        "[0]--->[1 0 0]\n",
        "[1]--->[0 1 0]\n",
        "[2]--->[0 0 1]\n",
        "'''\n",
        "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "PRHAtZlJLmiO"
      },
      "outputs": [],
      "source": [
        "examples = []\n",
        "for i in range(len(X_train)):\n",
        "    examples.append([X_train[i], y_train[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3M2ZcEjLvcS",
        "outputId": "e591b77f-7a98-4762-bea0-fb11af639dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0/500 | total error=-4.651952546939203e-05\n",
            "epoch 1/500 | total error=-4.644555092574975e-05\n",
            "epoch 2/500 | total error=-4.6376317941116087e-05\n",
            "epoch 3/500 | total error=-4.631278828678836e-05\n",
            "epoch 4/500 | total error=-4.625584776388955e-05\n",
            "epoch 5/500 | total error=-4.620627173456219e-05\n",
            "epoch 6/500 | total error=-4.616468565725821e-05\n",
            "epoch 7/500 | total error=-4.613151919120248e-05\n",
            "epoch 8/500 | total error=-4.6106952419867435e-05\n",
            "epoch 9/500 | total error=-4.609085272157971e-05\n",
            "epoch 10/500 | total error=-4.608270086112337e-05\n",
            "epoch 11/500 | total error=-4.608150503676162e-05\n",
            "epoch 12/500 | total error=-4.608570195785029e-05\n",
            "epoch 13/500 | total error=-4.609304463555943e-05\n",
            "epoch 14/500 | total error=-4.610047755373205e-05\n",
            "epoch 15/500 | total error=-4.6104001381160056e-05\n",
            "epoch 16/500 | total error=-4.609853153842621e-05\n",
            "epoch 17/500 | total error=-4.607775788391943e-05\n",
            "epoch 18/500 | total error=-4.603401663464679e-05\n",
            "epoch 19/500 | total error=-4.595819038008264e-05\n",
            "epoch 20/500 | total error=-4.583965747359438e-05\n",
            "epoch 21/500 | total error=-4.566631766244148e-05\n",
            "epoch 22/500 | total error=-4.542472554881031e-05\n",
            "epoch 23/500 | total error=-4.51003657984723e-05\n",
            "epoch 24/500 | total error=-4.467810180433287e-05\n",
            "epoch 25/500 | total error=-4.414378238293178e-05\n",
            "epoch 26/500 | total error=-4.348831677678892e-05\n",
            "epoch 27/500 | total error=-3.994236356428353e-05\n",
            "epoch 28/500 | total error=-3.397966595082014e-05\n",
            "epoch 29/500 | total error=-2.755908873399345e-05\n",
            "epoch 30/500 | total error=-2.0735123185887845e-05\n",
            "epoch 31/500 | total error=-1.3582381357341947e-05\n",
            "epoch 32/500 | total error=-6.187672590134604e-06\n",
            "epoch 33/500 | total error=3.563832281937481e-05\n",
            "epoch 34/500 | total error=0.00011824006750125089\n",
            "epoch 35/500 | total error=0.00020340525150736033\n",
            "epoch 36/500 | total error=0.0002901019384690719\n",
            "epoch 37/500 | total error=0.00037577987744083957\n",
            "epoch 38/500 | total error=0.0004598286579314705\n",
            "epoch 39/500 | total error=0.0005516398234398996\n",
            "epoch 40/500 | total error=0.0006456004856663071\n",
            "epoch 41/500 | total error=0.0007459507000752485\n",
            "epoch 42/500 | total error=0.0008489491456972059\n",
            "epoch 43/500 | total error=0.0009496406544311331\n",
            "epoch 44/500 | total error=0.001058353993448019\n",
            "epoch 45/500 | total error=0.0011687561205736005\n",
            "epoch 46/500 | total error=0.0012768921969168187\n",
            "epoch 47/500 | total error=0.0013825277744673385\n",
            "epoch 48/500 | total error=0.001485552826658132\n",
            "epoch 49/500 | total error=0.001592725885349272\n",
            "epoch 50/500 | total error=0.0017046558793989003\n",
            "epoch 51/500 | total error=0.0018135746359460646\n",
            "epoch 52/500 | total error=0.0019193648775896613\n",
            "epoch 53/500 | total error=0.0020227147707549873\n",
            "epoch 54/500 | total error=0.002124369080566768\n",
            "epoch 55/500 | total error=0.002223058455669476\n",
            "epoch 56/500 | total error=0.0023190606535938704\n",
            "epoch 57/500 | total error=0.0024124196402004073\n",
            "epoch 58/500 | total error=0.002503100888482371\n",
            "epoch 59/500 | total error=0.0025944776216222628\n",
            "epoch 60/500 | total error=0.0026836985418831182\n",
            "epoch 61/500 | total error=0.0027704755772733885\n",
            "epoch 62/500 | total error=0.0028548566258667753\n",
            "epoch 63/500 | total error=0.0029369710234269505\n",
            "epoch 64/500 | total error=0.0030171097540027244\n",
            "epoch 65/500 | total error=0.0030980693166111407\n",
            "epoch 66/500 | total error=0.0031770892312134665\n",
            "epoch 67/500 | total error=0.0032544062277948104\n",
            "epoch 68/500 | total error=0.0033300905470092677\n",
            "epoch 69/500 | total error=0.003405397746089591\n",
            "epoch 70/500 | total error=0.0034811826334799493\n",
            "epoch 71/500 | total error=0.0035345237250794435\n",
            "epoch 72/500 | total error=0.003570475199068428\n",
            "epoch 73/500 | total error=0.0036053386865565807\n",
            "epoch 74/500 | total error=0.0036401312495864912\n",
            "epoch 75/500 | total error=0.0036765959057913447\n",
            "epoch 76/500 | total error=0.003711949606851747\n",
            "epoch 77/500 | total error=0.003746195618993779\n",
            "epoch 78/500 | total error=0.0037793553088928465\n",
            "epoch 79/500 | total error=0.003812278623598506\n",
            "epoch 80/500 | total error=0.0038471505162214\n",
            "epoch 81/500 | total error=0.0038814004519392275\n",
            "epoch 82/500 | total error=0.003914728759317728\n",
            "epoch 83/500 | total error=0.003947093590273299\n",
            "epoch 84/500 | total error=0.003982020236591234\n",
            "epoch 85/500 | total error=0.004017628128839035\n",
            "epoch 86/500 | total error=0.004052320913512611\n",
            "epoch 87/500 | total error=0.004086101658084834\n",
            "epoch 88/500 | total error=0.004118974481441778\n",
            "epoch 89/500 | total error=0.004150944425201075\n",
            "epoch 90/500 | total error=0.004182017408346355\n",
            "epoch 91/500 | total error=0.0042121204256986245\n",
            "epoch 92/500 | total error=0.004241346339390434\n",
            "epoch 93/500 | total error=0.004269755909509573\n",
            "epoch 94/500 | total error=0.00429735606237287\n",
            "epoch 95/500 | total error=0.004324154354052454\n",
            "epoch 96/500 | total error=0.004350158878357767\n",
            "epoch 97/500 | total error=0.004375370363188836\n",
            "epoch 98/500 | total error=0.004399794989942285\n",
            "epoch 99/500 | total error=0.004423461584424289\n",
            "epoch 100/500 | total error=0.004446379744294558\n",
            "epoch 101/500 | total error=0.004468559380270313\n",
            "epoch 102/500 | total error=0.004490032112912433\n",
            "epoch 103/500 | total error=0.004510814269094334\n",
            "epoch 104/500 | total error=0.004530991797159115\n",
            "epoch 105/500 | total error=0.004550566407922783\n",
            "epoch 106/500 | total error=0.004569548981361282\n",
            "epoch 107/500 | total error=0.004587944406643003\n",
            "epoch 108/500 | total error=0.00460542251038446\n",
            "epoch 109/500 | total error=0.004604681382387041\n",
            "epoch 110/500 | total error=0.004603932187245164\n",
            "epoch 111/500 | total error=0.004603175170023299\n",
            "epoch 112/500 | total error=0.004602410543395104\n",
            "epoch 113/500 | total error=0.0046016384904275\n",
            "epoch 114/500 | total error=0.00460085916762383\n",
            "epoch 115/500 | total error=0.004600072707640698\n",
            "epoch 116/500 | total error=0.004599279221711068\n",
            "epoch 117/500 | total error=0.004598478706528344\n",
            "epoch 118/500 | total error=0.004597670973640158\n",
            "epoch 119/500 | total error=0.004596856145126707\n",
            "epoch 120/500 | total error=0.004596034316303016\n",
            "epoch 121/500 | total error=0.004595205562772923\n",
            "epoch 122/500 | total error=0.004594369942513616\n",
            "epoch 123/500 | total error=0.004593527497720442\n",
            "epoch 124/500 | total error=0.00459267819614572\n",
            "epoch 125/500 | total error=0.004591821680640992\n",
            "epoch 126/500 | total error=0.004590957989275236\n",
            "epoch 127/500 | total error=0.004590087157059876\n",
            "epoch 128/500 | total error=0.004589209204858099\n",
            "epoch 129/500 | total error=0.004588324140876043\n",
            "epoch 130/500 | total error=0.004587431674389983\n",
            "epoch 131/500 | total error=0.0045865317021798625\n",
            "epoch 132/500 | total error=0.004585624237927581\n",
            "epoch 133/500 | total error=0.004584709286971892\n",
            "epoch 134/500 | total error=0.004583786842826109\n",
            "epoch 135/500 | total error=0.004582856888429266\n",
            "epoch 136/500 | total error=0.0045819193972399756\n",
            "epoch 137/500 | total error=0.004580974334191847\n",
            "epoch 138/500 | total error=0.004580021656527805\n",
            "epoch 139/500 | total error=0.0045790613145284525\n",
            "epoch 140/500 | total error=0.004578093252147809\n",
            "epoch 141/500 | total error=0.004577117407568279\n",
            "epoch 142/500 | total error=0.004576133713684947\n",
            "epoch 143/500 | total error=0.004575142098528392\n",
            "epoch 144/500 | total error=0.004574142239020877\n",
            "epoch 145/500 | total error=0.004573133875317002\n",
            "epoch 146/500 | total error=0.004572116820207185\n",
            "epoch 147/500 | total error=0.004571090975567118\n",
            "epoch 148/500 | total error=0.0045700564822726735\n",
            "epoch 149/500 | total error=0.004569013326525234\n",
            "epoch 150/500 | total error=0.004567961478778074\n",
            "epoch 151/500 | total error=0.004566900895709891\n",
            "epoch 152/500 | total error=0.004565831521926039\n",
            "epoch 153/500 | total error=0.004564753291423372\n",
            "epoch 154/500 | total error=0.004563666111001035\n",
            "epoch 155/500 | total error=0.004562569627093496\n",
            "epoch 156/500 | total error=0.004561462967582764\n",
            "epoch 157/500 | total error=0.0045603460805175335\n",
            "epoch 158/500 | total error=0.004559219018406459\n",
            "epoch 159/500 | total error=0.004558081808431636\n",
            "epoch 160/500 | total error=0.004556934397866829\n",
            "epoch 161/500 | total error=0.004555776697599253\n",
            "epoch 162/500 | total error=0.004554608683953286\n",
            "epoch 163/500 | total error=0.004553430314175788\n",
            "epoch 164/500 | total error=0.004552241529287788\n",
            "epoch 165/500 | total error=0.004551042256288688\n",
            "epoch 166/500 | total error=0.0045498324100300335\n",
            "epoch 167/500 | total error=0.0045486118948076335\n",
            "epoch 168/500 | total error=0.004547380605713769\n",
            "epoch 169/500 | total error=0.0045461383617463845\n",
            "epoch 170/500 | total error=0.004544884993818088\n",
            "epoch 171/500 | total error=0.004543620392725609\n",
            "epoch 172/500 | total error=0.004542344441069214\n",
            "epoch 173/500 | total error=0.004541057014255913\n",
            "epoch 174/500 | total error=0.0045397579813478365\n",
            "epoch 175/500 | total error=0.0045384472057806175\n",
            "epoch 176/500 | total error=0.004537124545971327\n",
            "epoch 177/500 | total error=0.004535789855832776\n",
            "epoch 178/500 | total error=0.004534442985208459\n",
            "epoch 179/500 | total error=0.004533083780240204\n",
            "epoch 180/500 | total error=0.004531712083678838\n",
            "epoch 181/500 | total error=0.004530327735146631\n",
            "epoch 182/500 | total error=0.004528930571358929\n",
            "epoch 183/500 | total error=0.0045275204263112885\n",
            "epoch 184/500 | total error=0.004526097131437466\n",
            "epoch 185/500 | total error=0.004524660515742799\n",
            "epoch 186/500 | total error=0.004523210405916826\n",
            "epoch 187/500 | total error=0.004521746626428428\n",
            "epoch 188/500 | total error=0.004520268999606248\n",
            "epoch 189/500 | total error=0.004518777345706743\n",
            "epoch 190/500 | total error=0.004517271482971841\n",
            "epoch 191/500 | total error=0.004515751227677947\n",
            "epoch 192/500 | total error=0.004514216394177656\n",
            "epoch 193/500 | total error=0.0045126667949354216\n",
            "epoch 194/500 | total error=0.004511102240558229\n",
            "epoch 195/500 | total error=0.004509522539822131\n",
            "epoch 196/500 | total error=0.004507927499695361\n",
            "epoch 197/500 | total error=0.004506316925358721\n",
            "epoch 198/500 | total error=0.004504690620223674\n",
            "epoch 199/500 | total error=0.004503048385948737\n",
            "epoch 200/500 | total error=0.004501390022454438\n",
            "epoch 201/500 | total error=0.004499715327937272\n",
            "epoch 202/500 | total error=0.0044980240988828244\n",
            "epoch 203/500 | total error=0.004496316130078462\n",
            "epoch 204/500 | total error=0.004494591214625623\n",
            "epoch 205/500 | total error=0.004492849143952077\n",
            "epoch 206/500 | total error=0.004491089707824138\n",
            "epoch 207/500 | total error=0.00448931269435911\n",
            "epoch 208/500 | total error=0.004487517890037962\n",
            "epoch 209/500 | total error=0.004485705079718479\n",
            "epoch 210/500 | total error=0.004483874046648833\n",
            "epoch 211/500 | total error=0.004482024572481784\n",
            "epoch 212/500 | total error=0.004480156437289512\n",
            "epoch 213/500 | total error=0.004478269419579174\n",
            "epoch 214/500 | total error=0.00447636329630925\n",
            "epoch 215/500 | total error=0.004474437842906738\n",
            "epoch 216/500 | total error=0.0044724928332852435\n",
            "epoch 217/500 | total error=0.004470528039864004\n",
            "epoch 218/500 | total error=0.004468543233587948\n",
            "epoch 219/500 | total error=0.004466538183948736\n",
            "epoch 220/500 | total error=0.004464512659006953\n",
            "epoch 221/500 | total error=0.004462466425415355\n",
            "epoch 222/500 | total error=0.00446039924844335\n",
            "epoch 223/500 | total error=0.004458310892002615\n",
            "epoch 224/500 | total error=0.004456201118674023\n",
            "epoch 225/500 | total error=0.004454069689735762\n",
            "epoch 226/500 | total error=0.004451916365192878\n",
            "epoch 227/500 | total error=0.0044497409038080325\n",
            "epoch 228/500 | total error=0.004447543063133764\n",
            "epoch 229/500 | total error=0.0044453225995460775\n",
            "epoch 230/500 | total error=0.004443079268279553\n",
            "epoch 231/500 | total error=0.004440812823463872\n",
            "epoch 232/500 | total error=0.004438523018161905\n",
            "epoch 233/500 | total error=0.004436209604409317\n",
            "epoch 234/500 | total error=0.004433872333255784\n",
            "epoch 235/500 | total error=0.004431510954807769\n",
            "epoch 236/500 | total error=0.004429125218272998\n",
            "epoch 237/500 | total error=0.004426714872006553\n",
            "epoch 238/500 | total error=0.004424279663558706\n",
            "epoch 239/500 | total error=0.004421819339724421\n",
            "epoch 240/500 | total error=0.004419333646594723\n",
            "epoch 241/500 | total error=0.0044168223296097335\n",
            "epoch 242/500 | total error=0.004414285133613561\n",
            "epoch 243/500 | total error=0.004411721802911073\n",
            "epoch 244/500 | total error=0.004409132081326482\n",
            "epoch 245/500 | total error=0.00440651571226382\n",
            "epoch 246/500 | total error=0.004403872438769381\n",
            "epoch 247/500 | total error=0.0044012020035959915\n",
            "epoch 248/500 | total error=0.00439850414926939\n",
            "epoch 249/500 | total error=0.004395778618156443\n",
            "epoch 250/500 | total error=0.004393025152535464\n",
            "epoch 251/500 | total error=0.004390243494668462\n",
            "epoch 252/500 | total error=0.0043874333868755356\n",
            "epoch 253/500 | total error=0.004384594571611214\n",
            "epoch 254/500 | total error=0.004381726791542904\n",
            "epoch 255/500 | total error=0.004378829789631485\n",
            "epoch 256/500 | total error=0.004375903309213872\n",
            "epoch 257/500 | total error=0.00437294709408777\n",
            "epoch 258/500 | total error=0.0043699608885985584\n",
            "epoch 259/500 | total error=0.004366944437728232\n",
            "epoch 260/500 | total error=0.004363897487186478\n",
            "epoch 261/500 | total error=0.004360819783503942\n",
            "epoch 262/500 | total error=0.004357711074127578\n",
            "epoch 263/500 | total error=0.004354571107518138\n",
            "epoch 264/500 | total error=0.004351399633249797\n",
            "epoch 265/500 | total error=0.004348196402111901\n",
            "epoch 266/500 | total error=0.004344961166212856\n",
            "epoch 267/500 | total error=0.004341693679086095\n",
            "epoch 268/500 | total error=0.004338393695798163\n",
            "epoch 269/500 | total error=0.004335060973058883\n",
            "epoch 270/500 | total error=0.004331695269333622\n",
            "epoch 271/500 | total error=0.004328296344957555\n",
            "epoch 272/500 | total error=0.004324863962252006\n",
            "epoch 273/500 | total error=0.004321397885642758\n",
            "epoch 274/500 | total error=0.004317897881780402\n",
            "epoch 275/500 | total error=0.0043143637196625595\n",
            "epoch 276/500 | total error=0.004310795170758088\n",
            "epoch 277/500 | total error=0.004307192009133117\n",
            "epoch 278/500 | total error=0.004303554011578995\n",
            "epoch 279/500 | total error=0.004299880957741955\n",
            "epoch 280/500 | total error=0.004296172630254591\n",
            "epoch 281/500 | total error=0.004292428814869053\n",
            "epoch 282/500 | total error=0.004288649289634267\n",
            "epoch 283/500 | total error=0.0042848338325168255\n",
            "epoch 284/500 | total error=0.004280982244741271\n",
            "epoch 285/500 | total error=0.004277094329968672\n",
            "epoch 286/500 | total error=0.004273169894947426\n",
            "epoch 287/500 | total error=0.004269208749782283\n",
            "epoch 288/500 | total error=0.004265210708182485\n",
            "epoch 289/500 | total error=0.0042611755876927025\n",
            "epoch 290/500 | total error=0.004257103209910034\n",
            "epoch 291/500 | total error=0.004252993400689494\n",
            "epoch 292/500 | total error=0.004248845990340213\n",
            "epoch 293/500 | total error=0.0042446608138139155\n",
            "epoch 294/500 | total error=0.0042404377108871795\n",
            "epoch 295/500 | total error=0.004236176526338616\n",
            "epoch 296/500 | total error=0.004231877110121822\n",
            "epoch 297/500 | total error=0.004227539317534818\n",
            "epoch 298/500 | total error=0.004223177622128283\n",
            "epoch 299/500 | total error=0.004218775527554069\n",
            "epoch 300/500 | total error=0.004214331298555437\n",
            "epoch 301/500 | total error=0.004209845473999754\n",
            "epoch 302/500 | total error=0.004205318479210513\n",
            "epoch 303/500 | total error=0.004200750437315449\n",
            "epoch 304/500 | total error=0.004196138943918996\n",
            "epoch 305/500 | total error=0.00419148423913781\n",
            "epoch 306/500 | total error=0.004186787019433972\n",
            "epoch 307/500 | total error=0.0041820478425399765\n",
            "epoch 308/500 | total error=0.004177267155029254\n",
            "epoch 309/500 | total error=0.004172445314760322\n",
            "epoch 310/500 | total error=0.004167582609146831\n",
            "epoch 311/500 | total error=0.004162679270030263\n",
            "epoch 312/500 | total error=0.004157735485787536\n",
            "epoch 313/500 | total error=0.00415275141118915\n",
            "epoch 314/500 | total error=0.00414772717542716\n",
            "epoch 315/500 | total error=0.004142662888655077\n",
            "epoch 316/500 | total error=0.004137558647317305\n",
            "epoch 317/500 | total error=0.0041324145384947575\n",
            "epoch 318/500 | total error=0.004127230530946104\n",
            "epoch 319/500 | total error=0.004122006723117059\n",
            "epoch 320/500 | total error=0.004116743218344961\n",
            "epoch 321/500 | total error=0.004111440116027349\n",
            "epoch 322/500 | total error=0.004106097514633386\n",
            "epoch 323/500 | total error=0.004100715513753657\n",
            "epoch 324/500 | total error=0.0040952942157763865\n",
            "epoch 325/500 | total error=0.004089832842171123\n",
            "epoch 326/500 | total error=0.004084330216687458\n",
            "epoch 327/500 | total error=0.004078786891199766\n",
            "epoch 328/500 | total error=0.00407320326966437\n",
            "epoch 329/500 | total error=0.0040675797489478326\n",
            "epoch 330/500 | total error=0.004061916706505824\n",
            "epoch 331/500 | total error=0.004056214483212749\n",
            "epoch 332/500 | total error=0.00405047339134095\n",
            "epoch 333/500 | total error=0.004044693722291243\n",
            "epoch 334/500 | total error=0.004038875752810087\n",
            "epoch 335/500 | total error=0.00403301974998762\n",
            "epoch 336/500 | total error=0.004027125975274267\n",
            "epoch 337/500 | total error=0.0040211946877071825\n",
            "epoch 338/500 | total error=0.004015226146500369\n",
            "epoch 339/500 | total error=0.00400922061312253\n",
            "epoch 340/500 | total error=0.004003178352962133\n",
            "epoch 341/500 | total error=0.003997099636659957\n",
            "epoch 342/500 | total error=0.003990984741173478\n",
            "epoch 343/500 | total error=0.003984833950624817\n",
            "epoch 344/500 | total error=0.0039786475569737615\n",
            "epoch 345/500 | total error=0.003972425860549364\n",
            "epoch 346/500 | total error=0.00396616917046669\n",
            "epoch 347/500 | total error=0.003959877804950416\n",
            "epoch 348/500 | total error=0.0039535520915822304\n",
            "epoch 349/500 | total error=0.003947192367486063\n",
            "epoch 350/500 | total error=0.00394079897946207\n",
            "epoch 351/500 | total error=0.003934372284078295\n",
            "epoch 352/500 | total error=0.003927912647727057\n",
            "epoch 353/500 | total error=0.003921420446651766\n",
            "epoch 354/500 | total error=0.003914896066948697\n",
            "epoch 355/500 | total error=0.00390833940409473\n",
            "epoch 356/500 | total error=0.003901745266510143\n",
            "epoch 357/500 | total error=0.003895115227405549\n",
            "epoch 358/500 | total error=0.0038884506320018527\n",
            "epoch 359/500 | total error=0.0038817526455983587\n",
            "epoch 360/500 | total error=0.0038750222919809313\n",
            "epoch 361/500 | total error=0.0038682604840587546\n",
            "epoch 362/500 | total error=0.003861468048283981\n",
            "epoch 363/500 | total error=0.0038535304166445778\n",
            "epoch 364/500 | total error=0.00384436259674175\n",
            "epoch 365/500 | total error=0.0038351912588023415\n",
            "epoch 366/500 | total error=0.0038260171977040854\n",
            "epoch 367/500 | total error=0.0038168411411334275\n",
            "epoch 368/500 | total error=0.003807663725551385\n",
            "epoch 369/500 | total error=0.003798485516744409\n",
            "epoch 370/500 | total error=0.0037893070261814893\n",
            "epoch 371/500 | total error=0.003780128724008666\n",
            "epoch 372/500 | total error=0.0037709510493555273\n",
            "epoch 373/500 | total error=0.003761774418494009\n",
            "epoch 374/500 | total error=0.003752599231281949\n",
            "epoch 375/500 | total error=0.003743425876237319\n",
            "epoch 376/500 | total error=0.0037342547345198705\n",
            "epoch 377/500 | total error=0.0037250861830414954\n",
            "epoch 378/500 | total error=0.0037159205968817777\n",
            "epoch 379/500 | total error=0.003706758351150106\n",
            "epoch 380/500 | total error=0.003697599822406808\n",
            "epoch 381/500 | total error=0.0036884453897333396\n",
            "epoch 382/500 | total error=0.0036792954355230564\n",
            "epoch 383/500 | total error=0.0036701503460499245\n",
            "epoch 384/500 | total error=0.0036610105118604777\n",
            "epoch 385/500 | total error=0.003651876328025592\n",
            "epoch 386/500 | total error=0.0036427481942806735\n",
            "epoch 387/500 | total error=0.003633626515077725\n",
            "epoch 388/500 | total error=0.0036245116995670826\n",
            "epoch 389/500 | total error=0.0036154041615239145\n",
            "epoch 390/500 | total error=0.0036063043192307797\n",
            "epoch 391/500 | total error=0.0035972125953257317\n",
            "epoch 392/500 | total error=0.00358812941662325\n",
            "epoch 393/500 | total error=0.0035790552139138027\n",
            "epoch 394/500 | total error=0.003569990421746979\n",
            "epoch 395/500 | total error=0.0035609354782017194\n",
            "epoch 396/500 | total error=0.003551890824646866\n",
            "epoch 397/500 | total error=0.003542856905494161\n",
            "epoch 398/500 | total error=0.0035338341679460408\n",
            "epoch 399/500 | total error=0.0035248230617394424\n",
            "epoch 400/500 | total error=0.003515824038887084\n",
            "epoch 401/500 | total error=0.003506837935163763\n",
            "epoch 402/500 | total error=0.0034978655773216533\n",
            "epoch 403/500 | total error=0.0034889073960236955\n",
            "epoch 404/500 | total error=0.003479963825741785\n",
            "epoch 405/500 | total error=0.0034710353011749547\n",
            "epoch 406/500 | total error=0.0034621222573222514\n",
            "epoch 407/500 | total error=0.0034532251294824945\n",
            "epoch 408/500 | total error=0.0034443443531966635\n",
            "epoch 409/500 | total error=0.0034354803641460717\n",
            "epoch 410/500 | total error=0.003426633598017049\n",
            "epoch 411/500 | total error=0.003417804490340011\n",
            "epoch 412/500 | total error=0.00340898862565544\n",
            "epoch 413/500 | total error=0.003400183369478536\n",
            "epoch 414/500 | total error=0.003391390335411957\n",
            "epoch 415/500 | total error=0.003382610923972305\n",
            "epoch 416/500 | total error=0.003373846324747302\n",
            "epoch 417/500 | total error=0.0033650975620982495\n",
            "epoch 418/500 | total error=0.0033563655309061663\n",
            "epoch 419/500 | total error=0.003347651024502407\n",
            "epoch 420/500 | total error=0.0033389547564705783\n",
            "epoch 421/500 | total error=0.0033302773776458295\n",
            "epoch 422/500 | total error=0.0033216194893528755\n",
            "epoch 423/500 | total error=0.0033129816537008036\n",
            "epoch 424/500 | total error=0.003304364401575923\n",
            "epoch 425/500 | total error=0.0032957650438678637\n",
            "epoch 426/500 | total error=0.0032871750829893873\n",
            "epoch 427/500 | total error=0.003278596942104392\n",
            "epoch 428/500 | total error=0.0032700326102190758\n",
            "epoch 429/500 | total error=0.0032614837291145395\n",
            "epoch 430/500 | total error=0.0032529516692260765\n",
            "epoch 431/500 | total error=0.003244437588841136\n",
            "epoch 432/500 | total error=0.0032359424802503424\n",
            "epoch 433/500 | total error=0.0032274672056995246\n",
            "epoch 434/500 | total error=0.003219010324081198\n",
            "epoch 435/500 | total error=0.003210568069457405\n",
            "epoch 436/500 | total error=0.0032021420347473186\n",
            "epoch 437/500 | total error=0.003193733560717472\n",
            "epoch 438/500 | total error=0.0031853437800614718\n",
            "epoch 439/500 | total error=0.0031769736625100586\n",
            "epoch 440/500 | total error=0.0031686240499805662\n",
            "epoch 441/500 | total error=0.003160295363344722\n",
            "epoch 442/500 | total error=0.0031519841676946538\n",
            "epoch 443/500 | total error=0.0031436918116938403\n",
            "epoch 444/500 | total error=0.0031354194325998175\n",
            "epoch 445/500 | total error=0.0031271719751160636\n",
            "epoch 446/500 | total error=0.0031189458818448165\n",
            "epoch 447/500 | total error=0.0031107402433103474\n",
            "epoch 448/500 | total error=0.003102556076268596\n",
            "epoch 449/500 | total error=0.0030943942551167067\n",
            "epoch 450/500 | total error=0.0030862555417089394\n",
            "epoch 451/500 | total error=0.0030781406087034614\n",
            "epoch 452/500 | total error=0.003070050057826664\n",
            "epoch 453/500 | total error=0.0030619844341516498\n",
            "epoch 454/500 | total error=0.00305394423725301\n",
            "epoch 455/500 | total error=0.003045929929914946\n",
            "epoch 456/500 | total error=0.0030379419449242163\n",
            "epoch 457/500 | total error=0.003029980690365125\n",
            "epoch 458/500 | total error=0.0030220465537432297\n",
            "epoch 459/500 | total error=0.0030141399051944796\n",
            "epoch 460/500 | total error=0.003006261099980028\n",
            "epoch 461/500 | total error=0.002998410480424209\n",
            "epoch 462/500 | total error=0.002990588377418311\n",
            "epoch 463/500 | total error=0.0029827951115863794\n",
            "epoch 464/500 | total error=0.002975030994188238\n",
            "epoch 465/500 | total error=0.0029672963278180456\n",
            "epoch 466/500 | total error=0.0029595914069446183\n",
            "epoch 467/500 | total error=0.0029519165183288223\n",
            "epoch 468/500 | total error=0.002944271941346179\n",
            "epoch 469/500 | total error=0.0029366579482361615\n",
            "epoch 470/500 | total error=0.0029290748042951195\n",
            "epoch 471/500 | total error=0.0029215227680261624\n",
            "epoch 472/500 | total error=0.0029140020912559036\n",
            "epoch 473/500 | total error=0.0029065130192261995\n",
            "epoch 474/500 | total error=0.0028990557906670533\n",
            "epoch 475/500 | total error=0.002891630637855346\n",
            "epoch 476/500 | total error=0.0028842377866631786\n",
            "epoch 477/500 | total error=0.002876877456598731\n",
            "epoch 478/500 | total error=0.0028695498608416405\n",
            "epoch 479/500 | total error=0.002862255206274855\n",
            "epoch 480/500 | total error=0.0028549936935141815\n",
            "epoch 481/500 | total error=0.00284776551693641\n",
            "epoch 482/500 | total error=0.0028405708647069334\n",
            "epoch 483/500 | total error=0.0028334099188074115\n",
            "epoch 484/500 | total error=0.0028262828550638737\n",
            "epoch 485/500 | total error=0.0028191898431756623\n",
            "epoch 486/500 | total error=0.0028121310467452755\n",
            "epoch 487/500 | total error=0.0028051066233096425\n",
            "epoch 488/500 | total error=0.0027981167243725023\n",
            "epoch 489/500 | total error=0.00279116149543836\n",
            "epoch 490/500 | total error=0.002784241076047857\n",
            "epoch 491/500 | total error=0.0027773555998146663\n",
            "epoch 492/500 | total error=0.002770505194463824\n",
            "epoch 493/500 | total error=0.002763689981871738\n",
            "epoch 494/500 | total error=0.0027569100781074793\n",
            "epoch 495/500 | total error=0.0027501655934757284\n",
            "epoch 496/500 | total error=0.002743456632560994\n",
            "epoch 497/500 | total error=0.0027367832942734797\n",
            "epoch 498/500 | total error=0.0027301456718960243\n",
            "epoch 499/500 | total error=0.002723543853132615\n"
          ]
        }
      ],
      "source": [
        "net = Network([4, 7, 3], [Sigmoide,ReLu])\n",
        "net.backpropagation(0.1, examples, 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "ljBLb96oL5hY"
      },
      "outputs": [],
      "source": [
        "examples = []\n",
        "for i in range(len(X_test)):\n",
        "    examples.append([X_test[i], y_test[i]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuuZsMzJL-wK",
        "outputId": "a4e59983-653e-4ab0-9edb-17719fabafa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9\n"
          ]
        }
      ],
      "source": [
        "accuracy = net.accuracy(examples)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXFqRhWfMA-3",
        "outputId": "9ce750f7-acad-473b-b402-b79e2aeee61f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desired output: [0. 0. 1.]\n",
            "Index of output: 2\n"
          ]
        }
      ],
      "source": [
        "prediction = net.predict(X_test[1])\n",
        "print(f\"Desired output: {y_test[1]}\")\n",
        "print(f\"Index of output: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "kRCb_Au6oqQ8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   0  \\\n",
            "0                      0.07886412818583192 I:[] W:[]   \n",
            "1  0.6079603553260472 I:[0.07886412818583192 I:[]...   \n",
            "2  0 I:[0.6079603553260472 I:[0.07886412818583192...   \n",
            "\n",
            "                                                   1  \\\n",
            "0                       0.0661014913510784 I:[] W:[]   \n",
            "1  0.4082531171910942 I:[0.07886412818583192 I:[]...   \n",
            "2  0.735647828684781 I:[0.6079603553260472 I:[0.0...   \n",
            "\n",
            "                                                   2  \\\n",
            "0                      0.09838574584787062 I:[] W:[]   \n",
            "1  0.6354483587169235 I:[0.07886412818583192 I:[]...   \n",
            "2  0.8414844605876992 I:[0.6079603553260472 I:[0....   \n",
            "\n",
            "                                                   3  \\\n",
            "0                       0.1150242403183535 I:[] W:[]   \n",
            "1  0.5110481129110992 I:[0.07886412818583192 I:[]...   \n",
            "2                                               None   \n",
            "\n",
            "                                                   4  \\\n",
            "0                                               None   \n",
            "1  0.3898232533253635 I:[0.07886412818583192 I:[]...   \n",
            "2                                               None   \n",
            "\n",
            "                                                   5  \\\n",
            "0                                               None   \n",
            "1  0.3301118242826002 I:[0.07886412818583192 I:[]...   \n",
            "2                                               None   \n",
            "\n",
            "                                                   6  \n",
            "0                                               None  \n",
            "1  0.33470971081647877 I:[0.07886412818583192 I:[...  \n",
            "2                                               None  \n"
          ]
        }
      ],
      "source": [
        "#print(net.net)\n",
        "df = pd.DataFrame(net.net)\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
